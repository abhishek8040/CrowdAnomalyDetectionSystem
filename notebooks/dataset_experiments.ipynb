{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowd Anomaly Detection - Dataset Experiments\n",
    "\n",
    "This notebook explores various datasets for crowd analysis and anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Information\n",
    "\n",
    "### Recommended Datasets:\n",
    "\n",
    "1. **UCSD Pedestrian Dataset**\n",
    "   - Anomaly detection in pedestrian walkways\n",
    "   - http://www.svcl.ucsd.edu/projects/anomaly/dataset.htm\n",
    "\n",
    "2. **ShanghaiTech Dataset**\n",
    "   - Crowd counting and density estimation\n",
    "   - https://github.com/desenzhou/ShanghaiTechDataset\n",
    "\n",
    "3. **UCF-Crime Dataset**\n",
    "   - Anomaly detection in surveillance videos\n",
    "   - https://www.crcv.ucf.edu/projects/real-world/\n",
    "\n",
    "4. **CUHK Avenue Dataset**\n",
    "   - Abnormal event detection\n",
    "   - http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample video\n",
    "video_path = 'path/to/sample/video.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if ret:\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Sample Frame')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test YOLOv8 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Run inference\n",
    "results = model(frame)\n",
    "\n",
    "# Visualize results\n",
    "annotated = results[0].plot()\n",
    "plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "plt.title('YOLOv8 Detections')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowd Density Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract person detections\n",
    "person_boxes = []\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        if int(box.cls[0]) == 0:  # person class\n",
    "            person_boxes.append(box.xyxy[0].cpu().numpy())\n",
    "\n",
    "print(f\"Detected {len(person_boxes)} people\")\n",
    "\n",
    "# Visualize density heatmap\n",
    "density_map = np.zeros(frame.shape[:2], dtype=np.float32)\n",
    "\n",
    "for box in person_boxes:\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "    cv2.circle(density_map, (cx, cy), 50, 1, -1)\n",
    "\n",
    "density_map = cv2.GaussianBlur(density_map, (51, 51), 0)\n",
    "\n",
    "plt.imshow(density_map, cmap='hot')\n",
    "plt.colorbar(label='Density')\n",
    "plt.title('Crowd Density Heatmap')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation for Activity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Process first person\n",
    "if len(person_boxes) > 0:\n",
    "    x1, y1, x2, y2 = map(int, person_boxes[0])\n",
    "    person_crop = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    rgb_crop = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_crop)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        # Draw landmarks\n",
    "        annotated_crop = person_crop.copy()\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_crop,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS\n",
    "        )\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(annotated_crop, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Pose Estimation')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tracking over multiple frames\n",
    "from collections import defaultdict\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "track_history = defaultdict(list)\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 100\n",
    "\n",
    "while cap.isOpened() and frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Track with YOLOv8 built-in tracker\n",
    "    results = model.track(frame, persist=True)\n",
    "    \n",
    "    if results[0].boxes.id is not None:\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "        \n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x1, y1, x2, y2 = box\n",
    "            cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "            track_history[track_id].append((cx, cy))\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Visualize tracks\n",
    "plt.figure(figsize=(12, 8))\n",
    "for track_id, positions in track_history.items():\n",
    "    positions = np.array(positions)\n",
    "    plt.plot(positions[:, 0], positions[:, 1], marker='o', label=f'Track {track_id}')\n",
    "\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Object Trajectories')\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Loading and processing video data\n",
    "- Person detection with YOLOv8\n",
    "- Crowd density estimation\n",
    "- Pose estimation for activity analysis\n",
    "- Multi-object tracking\n",
    "\n",
    "Use these techniques as building blocks for the full anomaly detection system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
